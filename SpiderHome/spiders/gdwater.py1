# -*- coding: utf-8 -*-
from datetime import datetime, timedelta
from re import findall, sub
from time import sleep

from bs4 import BeautifulSoup as BS
from scrapy import Request
from scrapy.http import FormRequest
from scrapy.spiders import Spider

from SpiderHome.items import GdwaterItem


class GdwaterSpider(Spider):
    queue = [0]
    name = 'gdwater'
    custom_settings = {
        'ITEM_PIPELINES': {
            'SpiderHome.pipelines.GdwaterPipeline': 300,
        },
    }
    day1 = datetime(2017, 4, 1, 0, 0)
    day2 = datetime(2011, 9, 9, 0, 0)
    form = {
        '__EVENTVALIDATION': '',
        '__VIEWSTATE': '',
        'btn_query': '查询',
        'ddl_addvcd': '',
        'hidsearch': '',
        'txt_search': '',
        'txt_time1': (day1 - timedelta(hours=1)).strftime("%Y-%m-%d %H:%M"),
        'txt_time2': day1.strftime("%Y-%m-%d %H:%M")
    }
    url = 'http://www.gdwater.gov.cn:9001/Report/WaterReport.aspx'

    def start_requests(self):
        yield Request(self.url, callback=self.parse)

    def parse(self, response):
        soup = BS(response.body, 'lxml', from_encoding='utf-8')
        self.form['__EVENTVALIDATION'] = soup.find(
            'input', id='__EVENTVALIDATION')['value']
        self.form['__VIEWSTATE'] = soup.find(
            'input', id='__VIEWSTATE')['value']
        while self.day1 > self.day2:
            self.form['txt_time2'] = (
                self.day1 - timedelta(hours=1)).strftime("%Y-%m-%d %H:%M")
            self.form['txt_time1'] = self.day1.strftime("%Y-%m-%d %H:%M")
            while len(self.queue) == 0:
                sleep(10)
            self.queue.pop()
            sleep(2)
            print(self.day1.strftime("%Y-%m-%d %H:%M"))
            self.day1 = self.day1 - timedelta(hours=1)
            yield FormRequest(
                url=self.url, formdata=self.form, callback=self.second_parse)

    def second_parse(self, response):
        print('in')
        soup = BS(response.body, 'lxml')
        div = soup.find('div', id='LeftTree')
        tbody1 = div.find('tbody')
        trs = tbody1.find_all('tr')
        trs.reverse()
        trs.pop()
        self.queue.append(1)
        for tr in trs:
            tds = tr.find_all('td')
            item = GdwaterItem()
            item['thread'] = 'river'
            item['city'] = tds[0].get_text().strip()
            item['county'] = tds[1].get_text().strip()
            item['site'] = tds[2].get_text().strip()
            item['time'] = tds[3].get_text().strip()
            item['water_level'] = tds[4].get_text().strip()
            item['warning_level'] = tds[5].get_text().strip()
            item['water_potemtial'] = tds[6].get_text().strip()
            yield item
        div = soup.find('div', id='RightTree')
        trs = div.find_all('tr')
        trs.reverse()
        trs.pop()
        trs.pop()
        for tr in trs:
            tds = tr.find_all('td')
            item = GdwaterItem()
            item['thread'] = 'Reservoir'
            item['city'] = tds[0].get_text().strip()
            item['county'] = tds[1].get_text().strip()
            item['site'] = tds[2].get_text().strip()
            item['time'] = tds[3].get_text().strip()
            item['water_level'] = tds[4].get_text().strip()
            item['flood_limit_water_level'] = tds[5].get_text().strip()
            yield item
